{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_conll import ConllFormatter\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = 'PhD degree in Material Science, Polymer Science, Chemical Engineering or Chemistry Discipline.'\n",
    "string2 = 'Strong knowledge in computer vision, including image registration, segmentation, classification, object detection.'\n",
    "string3 = '5 years plus experience in project management, six sigma and DOE is preferred.'\n",
    "string4 = 'Experience working with and extracting value from large、 disconnected、 unstructured datasets'\n",
    "string5 = 'Develop a test plan including functional QA, integration testing, string testing, ICAT, ECAT, etc.'\n",
    "string6 = 'Perform data analysis including data mapping, report analysis, interface definitions'\n",
    "string7 = 'Develop functional specifications in a team environment, as well as derive use cases where appropriate'\n",
    "\n",
    "test_list = [string1,string2,string3,string4,string5,string6,string7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = string2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 依存句法分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tStrong\tstrong\tADJ\tJJ\tDegree=pos\t2\tamod\t_\t_\n",
      "2\tknowledge\tknowledge\tNOUN\tNN\tNumber=sing\t0\tROOT\t_\t_\n",
      "3\tin\tin\tADP\tIN\t_\t2\tprep\t_\t_\n",
      "4\tcomputer\tcomputer\tNOUN\tNN\tNumber=sing\t5\tcompound\t_\t_\n",
      "5\tvision\tvision\tNOUN\tNN\tNumber=sing\t3\tpobj\t_\t_\n",
      "6\t,\t,\tPUNCT\t,\tPunctType=comm\t5\tpunct\t_\t_\n",
      "7\tincluding\tinclude\tVERB\tVBG\tVerbForm=part|Tense=pres|Aspect=prog\t5\tprep\t_\t_\n",
      "8\timage\timage\tNOUN\tNN\tNumber=sing\t9\tcompound\t_\t_\n",
      "9\tregistration\tregistration\tNOUN\tNN\tNumber=sing\t7\tpobj\t_\t_\n",
      "10\t,\t,\tPUNCT\t,\tPunctType=comm\t9\tpunct\t_\t_\n",
      "11\tsegmentation\tsegmentation\tNOUN\tNN\tNumber=sing\t9\tconj\t_\t_\n",
      "12\t,\t,\tPUNCT\t,\tPunctType=comm\t11\tpunct\t_\t_\n",
      "13\tclassification\tclassification\tNOUN\tNN\tNumber=sing\t11\tconj\t_\t_\n",
      "14\t,\t,\tPUNCT\t,\tPunctType=comm\t13\tpunct\t_\t_\n",
      "15\tobject\tobject\tNOUN\tNN\tNumber=sing\t16\tcompound\t_\t_\n",
      "16\tdetection\tdetection\tNOUN\tNN\tNumber=sing\t13\tconj\t_\t_\n",
      "17\t.\t.\tPUNCT\t.\tPunctType=peri\t2\tpunct\t_\t_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "conllformatter = ConllFormatter(nlp)\n",
    "nlp.add_pipe(conllformatter, after='parser')\n",
    "doc = nlp( string )\n",
    "conll = doc._.conll\n",
    "print(doc._.conll_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SINV\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (JJ strong) (NN knowledge))\n",
      "      (PP (IN in) (NP (NN computer) (NN vision))))\n",
      "    (VP\n",
      "      (, ,)\n",
      "      (S+VP (VBG including) (NP (NN image) (NN registration)))))\n",
      "  (, ,)\n",
      "  (VP (VBZ segmentation))\n",
      "  (, ,)\n",
      "  (VP (VBZ classification))\n",
      "  (, ,)\n",
      "  (NP (JJ object) (NN detection))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "from stat_parser import Parser\n",
    "parser = Parser()\n",
    "print( parser.parse(string) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 开源工具 的关键词识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strong knowledge, computer vision, image registration, segmentation, classification, object detection]\n"
     ]
    }
   ],
   "source": [
    "my_chunks_list = []\n",
    "roor_chunks_dict = {}\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    my_chunks_list.append( chunk.root )\n",
    "    roor_chunks_dict[chunk.root] = chunk\n",
    "\n",
    "print( [roor_chunks_dict[w] for w in my_chunks_list] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 句法分析器 的层次结构生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong knowledge\n",
      "Strong knowledge -> computer vision\n",
      "Strong knowledge -> computer vision -> image registration\n",
      "Strong knowledge -> computer vision -> segmentation\n",
      "Strong knowledge -> computer vision -> classification\n",
      "Strong knowledge -> computer vision -> object detection\n"
     ]
    }
   ],
   "source": [
    "Total_List = []\n",
    "\n",
    "for word in my_chunks_list:\n",
    "    temp_list = []\n",
    "    temp_list.append(word)\n",
    "#     print( word,'',end = '')\n",
    "    \n",
    "    while word != word.head:\n",
    "        \n",
    "        relation = word.dep_\n",
    "        word = word.head\n",
    "#         tree_set.append( word )\n",
    "        \n",
    "        if word in my_chunks_list and relation != 'conj':\n",
    "            temp_list.append(word)\n",
    "#             print(word,'',end = '')\n",
    "            \n",
    "    Total_List.append( temp_list[::-1] )\n",
    "    \n",
    "for l in Total_List:\n",
    "    l = [roor_chunks_dict[w].text for w in l]\n",
    "    print( ' -> '.join(l) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出结果转树状格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'children': [{'children': [{'children': [{'children': [],\n",
      "                                           'name': 'image registration'},\n",
      "                                          {'children': [],\n",
      "                                           'name': 'segmentation'},\n",
      "                                          {'children': [],\n",
      "                                           'name': 'classification'},\n",
      "                                          {'children': [],\n",
      "                                           'name': 'object detection'}],\n",
      "                             'name': 'computer vision'}],\n",
      "               'name': 'Strong knowledge'}],\n",
      " 'name': 'ROOT'}\n"
     ]
    }
   ],
   "source": [
    "processed_dict = {}\n",
    "processed_dict['ROOT'] = {'name':'ROOT','children':[]}\n",
    "\n",
    "for l in Total_List:\n",
    "    \n",
    "    last = 'ROOT'\n",
    "    for w in l:\n",
    "        if w not in processed_dict.keys():            \n",
    "            processed_dict[w] = {'name':roor_chunks_dict[w].text,'children':[]}\n",
    "            processed_dict[last]['children'].append( processed_dict[w] )\n",
    "            \n",
    "        last = w\n",
    "        \n",
    "pprint( processed_dict['ROOT'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "from nose.tools import assert_equal, assert_in\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = [processed_dict['ROOT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"a9c8a7b49cfc45ada37262a970e37ce4\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts'], function(echarts) {\n",
       "                var chart_a9c8a7b49cfc45ada37262a970e37ce4 = echarts.init(\n",
       "                    document.getElementById('a9c8a7b49cfc45ada37262a970e37ce4'), 'white', {renderer: 'canvas'});\n",
       "                var option_a9c8a7b49cfc45ada37262a970e37ce4 = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"tree\",\n",
       "            \"name\": \"\\u6280\\u80fd\\u6811\",\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"ROOT\",\n",
       "                    \"children\": [\n",
       "                        {\n",
       "                            \"name\": \"Strong knowledge\",\n",
       "                            \"children\": [\n",
       "                                {\n",
       "                                    \"name\": \"computer vision\",\n",
       "                                    \"children\": [\n",
       "                                        {\n",
       "                                            \"name\": \"image registration\",\n",
       "                                            \"children\": []\n",
       "                                        },\n",
       "                                        {\n",
       "                                            \"name\": \"segmentation\",\n",
       "                                            \"children\": []\n",
       "                                        },\n",
       "                                        {\n",
       "                                            \"name\": \"classification\",\n",
       "                                            \"children\": []\n",
       "                                        },\n",
       "                                        {\n",
       "                                            \"name\": \"object detection\",\n",
       "                                            \"children\": []\n",
       "                                        }\n",
       "                                    ]\n",
       "                                }\n",
       "                            ]\n",
       "                        }\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"symbol\": \"emptyCircle\",\n",
       "            \"symbolSize\": 18,\n",
       "            \"roam\": false,\n",
       "            \"expandAndCollapse\": true,\n",
       "            \"initialTreeDepth\": 10,\n",
       "            \"layout\": \"orthogonal\",\n",
       "            \"orient\": \"LR\",\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"leaves\": {\n",
       "                \"label\": {\n",
       "                    \"show\": true,\n",
       "                    \"position\": \"top\",\n",
       "                    \"margin\": 8\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [],\n",
       "            \"selected\": {}\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0\n",
       "    }\n",
       "};\n",
       "                chart_a9c8a7b49cfc45ada37262a970e37ce4.setOption(option_a9c8a7b49cfc45ada37262a970e37ce4);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x10cb1ef0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Tree().add(\n",
    "        series_name=\"技能树\",\n",
    "        data=TEST_DATA,\n",
    "        symbol='emptyCircle',\n",
    "        symbol_size =18,\n",
    "        initial_tree_depth=10,\n",
    "        label_opts=opts.LabelOpts(),\n",
    "        leaves_label_opts=opts.LabelOpts(),\n",
    "#         title_opts=opts.TitleOpts(title=\"技能树\")\n",
    "    )\n",
    "c.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "# ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prcess(string):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    conllformatter = ConllFormatter(nlp)\n",
    "    nlp.add_pipe(conllformatter, after='parser')\n",
    "    doc = nlp( string )\n",
    "    conll = doc._.conll\n",
    "    \n",
    "    \n",
    "    my_chunks_list = []\n",
    "    roor_chunks_dict = {}\n",
    "\n",
    "    for chunk in doc.noun_chunks:\n",
    "        my_chunks_list.append( chunk.root )\n",
    "        roor_chunks_dict[chunk.root] = chunk\n",
    "        \n",
    "        \n",
    "    Total_List = []\n",
    "    for word in my_chunks_list:\n",
    "        temp_list = []\n",
    "        temp_list.append(word)\n",
    "\n",
    "        while word != word.head:\n",
    "\n",
    "            relation = word.dep_\n",
    "            word = word.head\n",
    "\n",
    "            if word in my_chunks_list and relation != 'conj':\n",
    "                temp_list.append(word)\n",
    "\n",
    "        Total_List.append( temp_list[::-1] )\n",
    "        \n",
    "    for l in Total_List:\n",
    "        l = [roor_chunks_dict[w].text for w in l]\n",
    "        print( ' -> '.join(l) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "例句: PhD degree in Material Science, Polymer Science, Chemical Engineering or Chemistry Discipline.\n",
      "输出:\n",
      "PhD degree\n",
      "PhD degree -> Material Science\n",
      "PhD degree -> Polymer Science\n",
      "PhD degree -> Chemical Engineering\n",
      "PhD degree -> Chemistry Discipline\n",
      "====================================================================================================\n",
      "例句: Strong knowledge in computer vision, including image registration, segmentation, classification, object detection.\n",
      "输出:\n",
      "Strong knowledge\n",
      "Strong knowledge -> computer vision\n",
      "Strong knowledge -> computer vision -> image registration\n",
      "Strong knowledge -> computer vision -> segmentation\n",
      "Strong knowledge -> computer vision -> classification\n",
      "Strong knowledge -> computer vision -> object detection\n",
      "====================================================================================================\n",
      "例句: 5 years plus experience in project management, six sigma and DOE is preferred.\n",
      "输出:\n",
      "5 years\n",
      "experience\n",
      "5 years -> project management\n",
      "DOE\n",
      "====================================================================================================\n",
      "例句: Experience working with and extracting value from large、 disconnected、 unstructured datasets\n",
      "输出:\n",
      "Experience\n",
      "Experience -> value\n",
      "Experience -> large、 disconnected、 unstructured datasets\n",
      "====================================================================================================\n",
      "例句: Develop a test plan including functional QA, integration testing, string testing, ICAT, ECAT, etc.\n",
      "输出:\n",
      "a test plan\n",
      "a test plan -> functional QA\n",
      "a test plan -> integration testing\n",
      "a test plan -> string testing\n",
      "a test plan -> ICAT\n",
      "====================================================================================================\n",
      "例句: Perform data analysis including data mapping, report analysis, interface definitions\n",
      "输出:\n",
      "data analysis\n",
      "data analysis -> data mapping\n",
      "report\n",
      "report -> analysis\n",
      "report -> interface definitions\n",
      "====================================================================================================\n",
      "例句: Develop functional specifications in a team environment, as well as derive use cases where appropriate\n",
      "输出:\n",
      "functional specifications\n",
      "functional specifications -> a team environment\n",
      "derive use cases\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for s in test_list:\n",
    "    print('例句:',s)\n",
    "    print('输出:')\n",
    "    prcess(s)\n",
    "    print( '='* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
